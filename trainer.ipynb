{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from models.Flowestimator import FlowEstimator\n",
    "import pytorch_lightning as pl\n",
    "from utils.warper import warper\n",
    "from dataloader.sintelloader import SintelLoader\n",
    "from utils.photometricloss import photometricloss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.averagemeter import AverageMeter\n",
    "from torchvision.utils import make_grid\n",
    "from utils.flow2rgb import flow2rgb\n",
    "from utils.replicateto3channel import replicatechannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowTrainer(object):\n",
    "    def __init__(self):\n",
    "        super(FlowTrainer, self).__init__()\n",
    "        # not the best model...\n",
    "        self.model = FlowEstimator(shape = (256,256), \n",
    "                                   use_l2 = True, \n",
    "                                   channel_in = 3, \n",
    "                                   stride = 1, \n",
    "                                   kernel_size = 2, \n",
    "                                   use_cst = True)\n",
    "        self.optimizer = None\n",
    "        self.lr_scheduler = None\n",
    "        self.save_dir = None\n",
    "        \n",
    "        self.epoch = 1\n",
    "        \n",
    "        self.train_loader = SintelLoader(batch_size = 20, \n",
    "                                         pin_memory = True, \n",
    "                                         num_workers = 8,\n",
    "                                        nsample=100)\n",
    "        \n",
    "        self.val_loader = None\n",
    "        \n",
    "        self.test_loader = SintelLoader(sintel_root=\"/data/keshav/sintel/test/final\",\n",
    "                                        batch_size = 1, \n",
    "                                        pin_memory = True, \n",
    "                                        num_workers = 8)\n",
    "        \n",
    "        self.sample_test = [*SintelLoader(sintel_root=\"/data/keshav/sintel/test/final\", \n",
    "                            test = True, nsample=10,visualize=True).load()][0]\n",
    "        self.sample_train = [*SintelLoader(nsample=10,visualize=True).load()][0]\n",
    "        \n",
    "        self.sample_val = None\n",
    "        \n",
    "        self.save_model_path = './best/'\n",
    "        self.load_model_path = None   \n",
    "        self.best_metrics = {'train_loss':None, \n",
    "                             'val_loss':None}\n",
    "        self.gpu_ids = [0,1,2,3,4,5,6,7]\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.02)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer)\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        self.photoloss = torch.nn.MSELoss()\n",
    "        \n",
    "        self.writer = SummaryWriter()\n",
    "        self.global_step = 0        \n",
    "        \n",
    "    def initialize(self):\n",
    "        self.model.to(self.device)\n",
    "        self.model = torch.nn.DataParallel(self.model, device_ids = self.gpu_ids)\n",
    "        if self.load_model_path:\n",
    "            #LOAD MODEL WEIGHTS HERE\n",
    "            pass\n",
    "        self.initialized = True\n",
    "        \n",
    "    \n",
    "    def savemodel(self, metrics, compare = 'val_loss'):\n",
    "        #Save model in save_model_path\n",
    "        if self.best_metrics.get('val_loss') > metrics.get('val_loss'):\n",
    "            #save only if new metrics are low\n",
    "            self.best_metrics.update(metrics)\n",
    "            pass\n",
    "        else:\n",
    "            # Load from the best saved\n",
    "            pass\n",
    "        \n",
    "    def train_epoch_end(self,metrics):\n",
    "        self.model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            frame1 = self.sample_train['frame1'].to(self.device)\n",
    "            frame2 = self.sample_train['frame2'].to(self.device)\n",
    "            \n",
    "            flow, occ = self.model(frame1, frame2)\n",
    "            frame1_ = warper(flow, frame2)\n",
    "            print(occ.shape)\n",
    "            occ = replicatechannel(occ)\n",
    "            print(occ.shape)\n",
    "            print(self.sample_train['occlusion'].shape)\n",
    "            sampocc = replicatechannel(self.sample_train['occlusion'].cuda())\n",
    "            print(sampocc.shape)\n",
    "            occs = torch.cat([sampocc, occ])\n",
    "            \n",
    "            frames = torch.cat([frame1_, frame1, frame2])\n",
    "            frames = make_grid(frames, nrow=10).unsqueeze(0)\n",
    "            \n",
    "            flows = torch.cat([flow2rgb(flow.cpu()).cuda(),self.sample_train['flow'].cuda()])\n",
    "            flows = make_grid(flows, nrow = 10).unsqueeze(0)\n",
    "            \n",
    "            self.writer.add_images('TRAIN/Frames',frames,metrics.get('nb_batch'))\n",
    "            self.writer.add_images('TRAIN/Flows',flows,metrics.get('nb_batch'))\n",
    "            self.writer.add_images('TRAIN/Occlusions',occs,metrics.get('nb_batch'))\n",
    "        \n",
    "        return self.val(metrics)\n",
    "    \n",
    "    def val_end(self,metrics):\n",
    "        return metrics\n",
    "        \n",
    "\n",
    "            \n",
    "    \n",
    "    def test_end(self,metrics):\n",
    "        with torch.no_grad():\n",
    "            frame1 = self.sample_test['frame1'].to(self.device)\n",
    "            frame2 = self.sample_test['frame2'].to(self.device)\n",
    "            \n",
    "            flow, occ = self.model(frame1, frame2)\n",
    "            frame1_ = warper(flow, frame2)\n",
    "            occ = replicatechannel(occ)\n",
    "            \n",
    "            frames = torch.cat([frame1_, frame1, frame2, flow2rgb(flow.cpu()).cuda(),occ])\n",
    "            frames = make_grid(frames, nrow=10).unsqueeze(0)\n",
    "            \n",
    "            self.writer.add_images('TEST/Frames',frames,metrics.get('nb_batch'))\n",
    "        return metrics\n",
    "            \n",
    "    \n",
    "    def train(self, nb_epoch):\n",
    "        trainstream = tqdm(self.train_loader.load())\n",
    "        self.avg_loss = AverageMeter()\n",
    "        self.model.train()\n",
    "        for i,data in enumerate(trainstream):\n",
    "            self.global_step += 1\n",
    "            trainstream.set_description('TRAINING')\n",
    "            \n",
    "            #GET X and Frame 2\n",
    "            #wdt = data['displacement'].to(self.device)\n",
    "            frame2 = data['frame2'].to(self.device)\n",
    "            frame1 = data['frame1'].to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            #forward\n",
    "            with torch.set_grad_enabled(True):\n",
    "                flow, occ = self.model(frame1, frame2)\n",
    "                frame1_ = warper(flow, frame2)\n",
    "                loss = photometricloss(frame1, frame1_, occ)\n",
    "                self.avg_loss.update(loss.item(),i+1)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                self.writer.add_scalar('Loss/train', \n",
    "                                       self.avg_loss.avg, self.global_step)\n",
    "                \n",
    "                trainstream.set_postfix({'epoch':nb_epoch, \n",
    "                                         'loss':self.avg_loss.avg})\n",
    "        self.scheduler.step(loss)\n",
    "        trainstream.close()            \n",
    "        return self.train_epoch_end({'TRloss':self.avg_loss.avg,'epoch':nb_epoch,})\n",
    "\n",
    "    \n",
    "    def val(self,metrics):\n",
    "        if self.val_loader is None:return self.test(metrics)\n",
    "        #DO VAL STUFF HERE\n",
    "        valstream = tqdm(self.val_loader.load())\n",
    "        for data in valstream:\n",
    "            pass\n",
    "        return self.val_end(metrics)\n",
    "    \n",
    "    def test(self, metrics = {}):\n",
    "        teststream = tqdm(self.test_loader.load())\n",
    "        self.avg_loss = AverageMeter()\n",
    "        with torch.no_grad():\n",
    "            for i,data in enumerate(teststream):\n",
    "                teststream.set_description('TESTING')\n",
    "                frame2 = data['frame2'].to(self.device)\n",
    "                frame1 = data['frame1'].to(self.device)\n",
    "                flow, occ = self.model(frame1, frame2)\n",
    "                frame1_ = warper(flow, frame2)\n",
    "                loss = photometricloss(frame1, frame1_, occ)\n",
    "                self.avg_loss.update(loss.item(),i+1)\n",
    "                metrics.update({'TSloss':self.avg_loss.avg})\n",
    "                teststream.set_postfix(metrics)\n",
    "        \n",
    "        self.writer.add_scalar('Loss/test', self.avg_loss.avg)\n",
    "        teststream.close()\n",
    "        \n",
    "        return self.test_end(metrics)    \n",
    "    \n",
    "    def loggings(self,**metrics):\n",
    "        pass\n",
    "    \n",
    "    def run(self):\n",
    "        self.initialize()\n",
    "        for i in range(self.epoch):\n",
    "            metrics = self.train(i)\n",
    "        self.test(metrics)\n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = FlowTrainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING: 100%|██████████| 1/1 [00:37<00:00, 37.35s/it, epoch=0, loss=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 256, 256])\n",
      "torch.Size([10, 3, 256, 256])\n",
      "torch.Size([10, 1, 256, 256])\n",
      "torch.Size([10, 3, 256, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TESTING: 100%|██████████| 552/552 [00:06<00:00, 89.49it/s, TRloss=nan, epoch=0, TSloss=nan] \n",
      "TESTING: 100%|██████████| 552/552 [00:06<00:00, 81.21it/s, TRloss=nan, epoch=0, TSloss=nan] \n"
     ]
    }
   ],
   "source": [
    "ft.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToPILImage, ToTensor\n",
    "import torch\n",
    "tostr = lambda x:int(''.join(re.findall(r'\\d+',x.as_posix())))\n",
    "maptotensor = lambda x:ToTensor()(Image.open(x).resize((256,256))).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "pth = [*Path(\"/data/keshav/sintel/training/occlusions/alley_1/\").glob('./*.png')]\n",
    "pth = [*map(lambda x:x.as_posix(),sorted(pth, key = tostr))]\n",
    "pth = pth[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occten = torch.cat([*map(maptotensor, pth)],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ToPILImage()(occten[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occbig = occten.view(1,-1).repeat(3,1).view(3,5,256,256).permute(1,0,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occbig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ToPILImage()(occbig[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "        self.conv11 = nn.Conv2d(1, 128, kernel_size=3, padding=1)\n",
    "        self.conv12 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv13 = nn.Conv2d(256, 2, kernel_size=3, padding=1)  \n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "\n",
    "        x = F.relu(self.conv11(x))\n",
    "        x = F.relu(self.conv12(x))\n",
    "        x = F.relu(self.conv13(x))\n",
    "\n",
    "        x = F.softmax(x, 1) #this line is changed\n",
    "\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "inputs = 0.5 - torch.rand(1,1,4,4)\n",
    "print(inputs)\n",
    "out = net(inputs)\n",
    "print (out)\n",
    "out.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention",
   "language": "python",
   "name": "attention"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
