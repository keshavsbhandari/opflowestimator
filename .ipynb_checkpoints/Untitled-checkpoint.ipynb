{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from utils.flowread import getflow\n",
    "from utils.flow2rgb import flow2rgb\n",
    "from utils.warper import warper\n",
    "from torchvision.transforms import ToPILImage, ToTensor\n",
    "from PIL import Image\n",
    "from utils.censustransform import censustransform\n",
    "from models.Unet import UNet\n",
    "\n",
    "toimage = ToPILImage()\n",
    "totensor = ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def contracting_block(self, in_channels, out_channels, kernel_size=3):\n",
    "        block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "        return block\n",
    "\n",
    "\n",
    "    def expansive_final(self, in_channels, mid_channels, out_channels, kernel_size=3):\n",
    "        block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channels[0]),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.BatchNorm2d(mid_channels[0]),\n",
    "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channels[0], out_channels=mid_channels[1]),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.BatchNorm2d(mid_channels[1]),\n",
    "            torch.nn.ConvTranspose2d(in_channels=mid_channels[1], out_channels=out_channels, kernel_size=3, stride=2,\n",
    "                                     padding=1, output_padding=1)\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n",
    "        block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.BatchNorm2d(mid_channel),\n",
    "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.BatchNorm2d(mid_channel),\n",
    "            torch.nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, kernel_size=3, stride=2,\n",
    "                                     padding=1, output_padding=1)\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n",
    "        block = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.BatchNorm2d(mid_channel),\n",
    "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.BatchNorm2d(mid_channel),\n",
    "            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\n",
    "            torch.nn.LeakyReLU(),\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(UNet, self).__init__()\n",
    "        # Encode\n",
    "        self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=64)\n",
    "        self.conv_maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_encode2 = self.contracting_block(64, 128)\n",
    "        self.conv_maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_encode3 = self.contracting_block(128, 256)\n",
    "        self.conv_maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        # Bottleneck\n",
    "        self.bottleneck = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(kernel_size=3, in_channels=256, out_channels=512),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.BatchNorm2d(512),\n",
    "            torch.nn.Conv2d(kernel_size=3, in_channels=512, out_channels=512),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.BatchNorm2d(512),\n",
    "            torch.nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, padding=1,\n",
    "                                     output_padding=1)\n",
    "        )\n",
    "        # Decode\n",
    "        self.conv_decode3 = self.expansive_block(512, 256, 128)\n",
    "        self.conv_decode2 = self.expansive_block(256, 128, 64)\n",
    "        self.final_layer = self.final_block(128, 64, out_channel)\n",
    "        self.expansive_final_block = self.expansive_final(out_channel,[32,8],out_channels=2)\n",
    "        \n",
    "        self.pyramid_feature1 = nn.Conv2d(in_channels = 64, out_channels=2, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.pyramid_feature2 = nn.Conv2d(in_channels = 128, out_channels=2, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.pyramid_feature3 = nn.Conv2d(in_channels = 256, out_channels=2, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.pyramid_feature4 = nn.Conv2d(in_channels = 256, out_channels=2, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.pyramid_feature5 = nn.Conv2d(in_channels = 128, out_channels=2, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.pyramid_feature6 = nn.Conv2d(in_channels = 64, out_channels=2, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "    def crop_and_concat(self, upsampled, bypass, crop=True):\n",
    "        if crop:\n",
    "            c = (bypass.size()[2] - upsampled.size()[2]) // 2\n",
    "            d = bypass.size(2) - upsampled.size(2) - c\n",
    "            bypass = bypass[:,:,c:-d,c:-d]\n",
    "        return torch.cat((upsampled, bypass), 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        # Encode\n",
    "        encode_block1 = self.conv_encode1(x)\n",
    "        encode_pool1 = self.conv_maxpool1(encode_block1) #go to pyramid1, [3, 64, 126, 126]\n",
    "        \n",
    "        \n",
    "        \n",
    "        encode_block2 = self.conv_encode2(encode_pool1)\n",
    "        encode_pool2 = self.conv_maxpool2(encode_block2)#go to pyramid2, [3, 128, 61, 61]\n",
    "        \n",
    "        \n",
    "        encode_block3 = self.conv_encode3(encode_pool2)\n",
    "        encode_pool3 = self.conv_maxpool3(encode_block3)#go to pyramid3,[ 3, 256, 28, 28]\n",
    "        \n",
    "        \n",
    "        # Bottleneck\n",
    "        bottleneck1 = self.bottleneck(encode_pool3)#go to pyramid4, [3, 256, 48, 48]\n",
    "        \n",
    "        \n",
    "        # Decode\n",
    "        decode_block3 = self.crop_and_concat(bottleneck1, encode_block3, crop=True)\n",
    "        cat_layer2 = self.conv_decode3(decode_block3)#go to pyramid 5, [3, 128, 88, 88]\n",
    "        \n",
    "        \n",
    "        decode_block2 = self.crop_and_concat(cat_layer2, encode_block2, crop=True)\n",
    "        cat_layer1 = self.conv_decode2(decode_block2)#go to pyramid 6, [3, 64, 168, 168]\n",
    "        \n",
    "        \n",
    "        \n",
    "        decode_block1 = self.crop_and_concat(cat_layer1, encode_block1, crop=True)\n",
    "        final_layer = self.final_layer(decode_block1)\n",
    "        \n",
    "        if self.training:\n",
    "            flow1 = self.pyramid_feature1(encode_block1)\n",
    "            flow2 = self.pyramid_feature2(encode_block1)\n",
    "            flow3 = self.pyramid_feature3(encode_block1)\n",
    "            flow4 = self.pyramid_feature4(encode_block1)\n",
    "            flow5 = self.pyramid_feature6(encode_block1)\n",
    "            flow6 = self.pyramid_feature6(encode_block1)\n",
    "            \n",
    "            return flow1,flow2,flow3,flow4,flow5,flow6,final_layer\n",
    "        else:\n",
    "            return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (conv_encode1): Sequential(\n",
      "    (0): Conv2d(8, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): LeakyReLU(negative_slope=0.01)\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv_maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv_encode2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): LeakyReLU(negative_slope=0.01)\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv_maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv_encode3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): LeakyReLU(negative_slope=0.01)\n",
      "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv_maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (bottleneck): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): LeakyReLU(negative_slope=0.01)\n",
      "    (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  )\n",
      "  (conv_decode3): Sequential(\n",
      "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): LeakyReLU(negative_slope=0.01)\n",
      "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  )\n",
      "  (conv_decode2): Sequential(\n",
      "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): LeakyReLU(negative_slope=0.01)\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  )\n",
      "  (final_layer): Sequential(\n",
      "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): LeakyReLU(negative_slope=0.01)\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (expansive_final_block): Sequential(\n",
      "    (0): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): LeakyReLU(negative_slope=0.01)\n",
      "    (5): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ConvTranspose2d(8, 2, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "  )\n",
      "  (pyramid_feature1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pyramid_feature2): Conv2d(128, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pyramid_feature3): Conv2d(256, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pyramid_feature4): Conv2d(128, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pyramid_feature5): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "False\n",
      "torch.Size([3, 64, 126, 126])\n",
      "torch.Size([3, 128, 61, 61])\n",
      "torch.Size([3, 256, 28, 28])\n",
      "torch.Size([3, 256, 48, 48])\n",
      "torch.Size([3, 128, 88, 88])\n",
      "torch.Size([3, 64, 168, 168])\n",
      "torch.Size([3, 8, 164, 164])\n"
     ]
    }
   ],
   "source": [
    "out = UNet(8,8)(torch.rand(3,8,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention",
   "language": "python",
   "name": "attention"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
